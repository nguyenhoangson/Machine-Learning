{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microsoft Kaggle Classification Challenge\n",
    "\n",
    "[Link](https://www.kaggle.com/c/malware-classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read and Examine Data Characteristics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Using pandas as Python Data Analysis Tools\n",
    "import pandas as pd\n",
    "\n",
    "submission_sample = pd.read_csv(\"./sampleSubmission/sampleSubmission.csv\")\n",
    "\n",
    "train_labels = pd.read_csv(\"./trainLabels/trainLabels.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10873, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction1</th>\n",
       "      <th>Prediction2</th>\n",
       "      <th>Prediction3</th>\n",
       "      <th>Prediction4</th>\n",
       "      <th>Prediction5</th>\n",
       "      <th>Prediction6</th>\n",
       "      <th>Prediction7</th>\n",
       "      <th>Prediction8</th>\n",
       "      <th>Prediction9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RYzecbHASsni7N51DrgB</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>y0iSXI1lwemrq39buQds</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OCsctgA5MWGXHP1vo0qx</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kGW27noyvwBUJXeMQzgI</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rHiws5yCIjSvcz1M0U8Q</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Id  Prediction1  Prediction2  Prediction3  Prediction4  \\\n",
       "0  RYzecbHASsni7N51DrgB     0.111111     0.111111     0.111111     0.111111   \n",
       "1  y0iSXI1lwemrq39buQds     0.111111     0.111111     0.111111     0.111111   \n",
       "2  OCsctgA5MWGXHP1vo0qx     0.111111     0.111111     0.111111     0.111111   \n",
       "3  kGW27noyvwBUJXeMQzgI     0.111111     0.111111     0.111111     0.111111   \n",
       "4  rHiws5yCIjSvcz1M0U8Q     0.111111     0.111111     0.111111     0.111111   \n",
       "\n",
       "   Prediction5  Prediction6  Prediction7  Prediction8  Prediction9  \n",
       "0     0.111111     0.111111     0.111111     0.111111     0.111111  \n",
       "1     0.111111     0.111111     0.111111     0.111111     0.111111  \n",
       "2     0.111111     0.111111     0.111111     0.111111     0.111111  \n",
       "3     0.111111     0.111111     0.111111     0.111111     0.111111  \n",
       "4     0.111111     0.111111     0.111111     0.111111     0.111111  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10868, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01kcPWA9K2BOxQeS5Rju</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04EjIdbPV5e1XroFOpiN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05EeG39MTRrI6VY21DPd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05rJTUWYAKNegBk2wE8X</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0AnoOZDNbPXIr2MRBSCJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0AwWs42SUQ19mI7eDcTC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0cH8YeO15ZywEhPrJvmj</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0DNVFKwYlcjO7bTfJ5p1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0DqUX5rkg3IbMY6BLGCE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0eaNKwluUmkYdIvZ923c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Id  Class\n",
       "0  01kcPWA9K2BOxQeS5Rju      1\n",
       "1  04EjIdbPV5e1XroFOpiN      1\n",
       "2  05EeG39MTRrI6VY21DPd      1\n",
       "3  05rJTUWYAKNegBk2wE8X      1\n",
       "4  0AnoOZDNbPXIr2MRBSCJ      1\n",
       "5  0AwWs42SUQ19mI7eDcTC      1\n",
       "6  0cH8YeO15ZywEhPrJvmj      1\n",
       "7  0DNVFKwYlcjO7bTfJ5p1      1\n",
       "8  0DqUX5rkg3IbMY6BLGCE      1\n",
       "9  0eaNKwluUmkYdIvZ923c      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mock data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.995531</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.001433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.994200</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.001835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.994277</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.001835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.994965</td>\n",
       "      <td>0.001611</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035030</td>\n",
       "      <td>0.890084</td>\n",
       "      <td>0.039638</td>\n",
       "      <td>0.035247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.994965</td>\n",
       "      <td>0.001611</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.994277</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.001835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.995909</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>0.001434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001820</td>\n",
       "      <td>0.992385</td>\n",
       "      <td>0.003963</td>\n",
       "      <td>0.001832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001813</td>\n",
       "      <td>0.988179</td>\n",
       "      <td>0.007462</td>\n",
       "      <td>0.002547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.994957</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.001432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001817</td>\n",
       "      <td>0.990638</td>\n",
       "      <td>0.005717</td>\n",
       "      <td>0.001828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.994277</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.001835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.994277</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.001835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.993554</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.002561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.995343</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>0.002001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.993254</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.002163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.991398</td>\n",
       "      <td>0.003440</td>\n",
       "      <td>0.003016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.994298</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.001999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.995531</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.001433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.002282</td>\n",
       "      <td>0.990452</td>\n",
       "      <td>0.004969</td>\n",
       "      <td>0.002297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.014554</td>\n",
       "      <td>0.900606</td>\n",
       "      <td>0.070196</td>\n",
       "      <td>0.014644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.979920</td>\n",
       "      <td>0.016474</td>\n",
       "      <td>0.001809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.010657</td>\n",
       "      <td>0.884566</td>\n",
       "      <td>0.094053</td>\n",
       "      <td>0.010724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.002692</td>\n",
       "      <td>0.969928</td>\n",
       "      <td>0.024672</td>\n",
       "      <td>0.002709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.001988</td>\n",
       "      <td>0.918352</td>\n",
       "      <td>0.077660</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.001825</td>\n",
       "      <td>0.994761</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.001836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.015455</td>\n",
       "      <td>0.950843</td>\n",
       "      <td>0.018150</td>\n",
       "      <td>0.015551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.993254</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.002163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.993543</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.001834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.995280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.004833</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.991367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.012126</td>\n",
       "      <td>0.028752</td>\n",
       "      <td>0.073681</td>\n",
       "      <td>0.885441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.050380</td>\n",
       "      <td>0.946145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.007817</td>\n",
       "      <td>0.020032</td>\n",
       "      <td>0.968854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.001268</td>\n",
       "      <td>0.003548</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>0.993235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>0.011051</td>\n",
       "      <td>0.985229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.994889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.002335</td>\n",
       "      <td>0.007671</td>\n",
       "      <td>0.988732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>0.002840</td>\n",
       "      <td>0.993798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.003357</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>0.003799</td>\n",
       "      <td>0.986635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.002093</td>\n",
       "      <td>0.003872</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.990679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.002843</td>\n",
       "      <td>0.994888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.013471</td>\n",
       "      <td>0.031942</td>\n",
       "      <td>0.011649</td>\n",
       "      <td>0.942938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.002279</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.992853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.002120</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>0.994895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.994889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.001268</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>0.993289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.005389</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.990372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.002330</td>\n",
       "      <td>0.995400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.003375</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.994258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.994621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>0.012909</td>\n",
       "      <td>0.984845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.002061</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.021156</td>\n",
       "      <td>0.975163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.995280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.994997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.994997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.010097</td>\n",
       "      <td>0.001480</td>\n",
       "      <td>0.987162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.987547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.995280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3\n",
       "0    0.001424  0.995531  0.001612  0.001433\n",
       "1    0.001824  0.994200  0.002142  0.001835\n",
       "2    0.001824  0.994277  0.002064  0.001835\n",
       "3    0.001423  0.994965  0.001611  0.002000\n",
       "4    0.035030  0.890084  0.039638  0.035247\n",
       "5    0.001423  0.994965  0.001611  0.002000\n",
       "6    0.001824  0.994277  0.002064  0.001835\n",
       "7    0.001425  0.995909  0.001232  0.001434\n",
       "8    0.001820  0.992385  0.003963  0.001832\n",
       "9    0.001813  0.988179  0.007462  0.002547\n",
       "10   0.001423  0.994957  0.002187  0.001432\n",
       "11   0.001817  0.990638  0.005717  0.001828\n",
       "12   0.001824  0.994277  0.002064  0.001835\n",
       "13   0.001824  0.994277  0.002064  0.001835\n",
       "14   0.001822  0.993554  0.002062  0.002561\n",
       "15   0.001424  0.995343  0.001231  0.002001\n",
       "16   0.002150  0.993254  0.002433  0.002163\n",
       "17   0.002146  0.991398  0.003440  0.003016\n",
       "18   0.001423  0.994298  0.002280  0.001999\n",
       "19   0.001424  0.995531  0.001612  0.001433\n",
       "20   0.002282  0.990452  0.004969  0.002297\n",
       "21   0.014554  0.900606  0.070196  0.014644\n",
       "22   0.001797  0.979920  0.016474  0.001809\n",
       "23   0.010657  0.884566  0.094053  0.010724\n",
       "24   0.002692  0.969928  0.024672  0.002709\n",
       "25   0.001988  0.918352  0.077660  0.002000\n",
       "26   0.001825  0.994761  0.001578  0.001836\n",
       "27   0.015455  0.950843  0.018150  0.015551\n",
       "28   0.002150  0.993254  0.002433  0.002163\n",
       "29   0.001822  0.993543  0.002800  0.001834\n",
       "..        ...       ...       ...       ...\n",
       "148  0.001271  0.002350  0.001099  0.995280\n",
       "149  0.002038  0.004833  0.001763  0.991367\n",
       "150  0.012126  0.028752  0.073681  0.885441\n",
       "151  0.001945  0.001530  0.050380  0.946145\n",
       "152  0.003297  0.007817  0.020032  0.968854\n",
       "153  0.001268  0.003548  0.001949  0.993235\n",
       "154  0.002082  0.001637  0.011051  0.985229\n",
       "155  0.001270  0.002349  0.001492  0.994889\n",
       "156  0.001262  0.002335  0.007671  0.988732\n",
       "157  0.001269  0.002093  0.002840  0.993798\n",
       "158  0.003357  0.006209  0.003799  0.986635\n",
       "159  0.002093  0.003872  0.003356  0.990679\n",
       "160  0.001270  0.000999  0.002843  0.994888\n",
       "161  0.013471  0.031942  0.011649  0.942938\n",
       "162  0.002279  0.001792  0.003077  0.992853\n",
       "163  0.001270  0.002120  0.001715  0.994895\n",
       "164  0.001270  0.002349  0.001492  0.994889\n",
       "165  0.001268  0.002345  0.003098  0.993289\n",
       "166  0.002273  0.005389  0.001966  0.990372\n",
       "167  0.001271  0.000999  0.002330  0.995400\n",
       "168  0.001269  0.003375  0.001098  0.994258\n",
       "169  0.001270  0.003011  0.001098  0.994621\n",
       "170  0.001257  0.000989  0.012909  0.984845\n",
       "171  0.002061  0.001620  0.021156  0.975163\n",
       "172  0.001271  0.002350  0.001099  0.995280\n",
       "173  0.001270  0.002634  0.001099  0.994997\n",
       "174  0.001270  0.002634  0.001099  0.994997\n",
       "175  0.001260  0.010097  0.001480  0.987162\n",
       "176  0.001261  0.010101  0.001090  0.987547\n",
       "177  0.001271  0.002350  0.001099  0.995280\n",
       "\n",
       "[178 rows x 4 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using mock data to test xgboost library\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set up mock data to test xgboost\n",
    "mock_data = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header=None)\n",
    "\n",
    "label = mock_data[0]\n",
    "\n",
    "# Convert DataFrame to equivalent Numpy-array representation\n",
    "data = mock_data.drop(0, 1).as_matrix()\n",
    "\n",
    "# Get the data in shape of DMatrix data structure to fit xgboost \n",
    "dtrain = xgb.DMatrix(data, label=label)\n",
    "\n",
    "# Set up hyper parameters\n",
    "params = {'max_depth':2, 'eta':1.0, 'silent':1, 'colsample_bytree': 1, 'objective':'multi:softprob',\n",
    "          'min_child_weight': 2, 'num_class': 4}\n",
    " \n",
    "num_round = 10\n",
    "\n",
    "# Train the model\n",
    "bst = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "# Make the predictions \n",
    "predictions = bst.predict(dtrain)\n",
    "\n",
    "# Transfomr the result\n",
    "pd.DataFrame(data=predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation - Using Multi Class Log Loss Metrics\n",
    "[Link](https://www.kaggle.com/c/malware-classification/details/evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "### Refer to file test_multi_class_loss.py with pytest 2.8.5 to run tests\n",
    "\n",
    "# Make multi class log loss function\n",
    "def multi_class_log_loss(actuals, predictions):\n",
    "    \"\"\" Implementation of multiclass log loss: \n",
    "    https://www.kaggle.com/wiki/MultiClassLogLoss.\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    ** actuals = numpy_array, shape = [n_samples, 1], \n",
    "              each_row_contains_true_class: integer from [0, n_classes - 1]\n",
    "    \n",
    "    ** predictions = numpy_array, shape = [n_samples, n_classes],\n",
    "                     each_row_contains_predicted_probablities: float in [0,1] and sum approximately to 1\n",
    "    \n",
    "    Return Type\n",
    "    -------------\n",
    "    ** loss = float\n",
    "    \"\"\"\n",
    "    \n",
    "    n_samples = actuals.shape[0]\n",
    "\n",
    "    # Auxiliary matrix for computational convenience purpose\n",
    "    auxiliary = np.zeros(predictions.shape)\n",
    "    auxiliary[np.arange(n_samples), actuals.astype(int)] = 1\n",
    "    \n",
    "    # Sum log\n",
    "    sum_log = np.sum(auxiliary*np.log(predictions))\n",
    "    \n",
    "    loss = (-1.0)/(n_samples)*sum_log\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22731585854657052"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Cross Validation\n",
    "from sklearn.cross_validation import KFold\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "\n",
    "# Set up mock data to test xgboost\n",
    "mock_data = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header=None)\n",
    "\n",
    "# Convert DataFrame to equivalent Numpy-array representation\n",
    "data = mock_data.drop(0, 1).as_matrix()\n",
    "\n",
    "# Set up labels \n",
    "label = mock_data[0]\n",
    "\n",
    "# Set up KFold\n",
    "kf = KFold(mock_data.shape[0], 5, shuffle=False, random_state=None)\n",
    "\n",
    "# Set up hyper parameters\n",
    "params = {'max_depth': 4, 'eta':1.0, 'silent':1, 'colsample_bytree': 1, 'objective':'multi:softprob',\n",
    "          'min_child_weight': 2, 'num_class': 4}\n",
    " \n",
    "num_round = 10\n",
    "\n",
    "# Initialize scores\n",
    "scores = np.array([])\n",
    "\n",
    "# Evaluate using log loss function for multi-class classification\n",
    "for train, test in kf:\n",
    "    train_set = data[train]\n",
    "    label_train = label[train]\n",
    "    test_set = data[test]\n",
    "    label_test = label[test].as_matrix()\n",
    "    \n",
    "    # Transform into the proper data shape\n",
    "    train_set = xgb.DMatrix(train_set, label=label_train)\n",
    "    test_set = xgb.DMatrix(test_set)\n",
    "    \n",
    "    # Train the model\n",
    "    bst = xgb.train(params, train_set, num_round)\n",
    "    \n",
    "    # Predict\n",
    "    predictions = bst.predict(test_set)\n",
    "    \n",
    "    # Calculate log loss\n",
    "    scores = np.append(scores, multi_class_log_loss(label_test, predictions))\n",
    "    \n",
    "\n",
    "# Print the mean multi class log loss\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3333333333333333"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([])\n",
    "a = np.append(a, 1)\n",
    "a = np.append(a, 2)\n",
    "a = np.append(a, 1)\n",
    "a.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Final Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Train the model into training data\n",
    "\n",
    "# Predict the test set\n",
    "\n",
    "# Transform the result into expected form\n",
    "\n",
    "# Get submitted csv file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
